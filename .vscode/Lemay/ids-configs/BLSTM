{
    "BLSTM": {
        "_type": "BLSTM",
        "model-file": "../models/blstm.model",
        "features": ["tcp_windowsize",
                    "tcp_window scale",
                    "tcp_Maximum segment size",
                    "tcp_Timestamps",
                    "tcp_sack_permitted",
                    "tcp_No-Operation (NOP)",
                    "holding.register.8",
                    "holding.register.9",
                    "holding.register.10",
                    "holding.register.11",
                    "discrete.input.4",
                    "discrete.input.5",
                    "discrete.input.6",
                    "discrete.input.7",
                    "coil.0",
                    "coil.1",
                    "coil.2",
                    "coil.3",
                    "coil.4",
                    "src",
                    "dest",
                    "length",
                    "protocol",
                    "activity"],
        "preprocessors": [
            {"method" : "label", "features" : ["tcp_sack_permitted","tcp_flags","src","dest","protocol","activity"]},
            {"method" : "indicate-none", "features" : [
                "tcp_window scale",
                "tcp_sack_permitted",
                "tcp_No-Operation (NOP)",
                "tcp_Timestamps",
                "tcp_Maximum segment size",
                "holding.register.8",
                "holding.register.9",
                "holding.register.10",
                "holding.register.11",
                "discrete.input.4",
                "discrete.input.5",
                "discrete.input.6",
                "discrete.input.7",
                "coil.0",
                "coil.1",
                "coil.2",
                "coil.3",
                "coil.4"]}
        ],
        "trainon": 1.0,
        "save-training": "../models/blstm.model",
        "allow-none": true,
        "learning_rate": [
            0.001,
            0.01,
            0.1
        ],
        "batch_size": [
            64,
            128,
            256
        ],
        "dropout": [
            0.0,
            0.1,
            0.2
        ],
        "hidden_layer_size": [
            64,
            128,
            256
        ],
        "epochs": 50,
        "sequence_length": 4,
        "step": 4,
        "verbose": 1,
        "adjust": true
    }
}